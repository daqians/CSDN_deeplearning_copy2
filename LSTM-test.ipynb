{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the word list!\n",
      "Loaded the word vectors!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "wordsList = np.load('./training_data/wordsList.npy')\n",
    "print('Loaded the word list!')\n",
    "wordsList = wordsList.tolist() #Originally loaded as numpy array\n",
    "wordsList = [word.decode('UTF-8') for word in wordsList] #Encode words as UTF-8\n",
    "wordVectors = np.load('./training_data/wordVectors.npy')\n",
    "print ('Loaded the word vectors!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n",
      "(400000, 50)\n"
     ]
    }
   ],
   "source": [
    "print(len(wordsList))\n",
    "print(wordVectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.93270004,  1.04209995, -0.78514999,  0.91033   ,  0.22711   ,\n",
       "       -0.62158   , -1.64929998,  0.07686   , -0.58679998,  0.058831  ,\n",
       "        0.35628   ,  0.68915999, -0.50598001,  0.70472997,  1.26639998,\n",
       "       -0.40031001, -0.020687  ,  0.80862999, -0.90565997, -0.074054  ,\n",
       "       -0.87674999, -0.62910002, -0.12684999,  0.11524   , -0.55685002,\n",
       "       -1.68260002, -0.26291001,  0.22632   ,  0.713     , -1.08280003,\n",
       "        2.12310004,  0.49869001,  0.066711  , -0.48225999, -0.17896999,\n",
       "        0.47699001,  0.16384   ,  0.16537   , -0.11506   , -0.15962   ,\n",
       "       -0.94926   , -0.42833   , -0.59456998,  1.35660005, -0.27506   ,\n",
       "        0.19918001, -0.36008   ,  0.55667001, -0.70314997,  0.17157   ], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseballIndex = wordsList.index('baseball')\n",
    "wordVectors[baseballIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "[    41    804 201534   1005     15   7446      5  13767      0      0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "maxSeqLength = 10 #Maximum length of sentence\n",
    "numDimensions = 300 #Dimensions for each word vector\n",
    "firstSentence = np.zeros((maxSeqLength), dtype='int32')\n",
    "firstSentence[0] = wordsList.index(\"i\")\n",
    "firstSentence[1] = wordsList.index(\"thought\")\n",
    "firstSentence[2] = wordsList.index(\"the\")\n",
    "firstSentence[3] = wordsList.index(\"movie\")\n",
    "firstSentence[4] = wordsList.index(\"was\")\n",
    "firstSentence[5] = wordsList.index(\"incredible\")\n",
    "firstSentence[6] = wordsList.index(\"and\")\n",
    "firstSentence[7] = wordsList.index(\"inspiring\")\n",
    "#firstSentence[8] and firstSentence[9] are going to be 0\n",
    "print(firstSentence.shape)\n",
    "print(firstSentence) #Shows the row index for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 50)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(tf.nn.embedding_lookup(wordVectors,firstSentence).eval().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive files finished\n",
      "Negative files finished\n",
      "The total number of files is 25000\n",
      "The total number of words in the files is 5844680\n",
      "The average number of words in the files is 233.7872\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "positiveFiles = ['./training_data/positiveReviews/' + f for f in listdir('./training_data/positiveReviews/') if isfile(join('./training_data/positiveReviews/', f))]\n",
    "negativeFiles = ['./training_data/negativeReviews/' + f for f in listdir('./training_data/negativeReviews/') if isfile(join('./training_data/negativeReviews/', f))]\n",
    "numWords = []\n",
    "for pf in positiveFiles:\n",
    "    with open(pf, \"r\", encoding='utf-8') as f:\n",
    "        line=f.readline()\n",
    "        counter = len(line.split())\n",
    "        numWords.append(counter)       \n",
    "print('Positive files finished')\n",
    "\n",
    "for nf in negativeFiles:\n",
    "    with open(nf, \"r\", encoding='utf-8') as f:\n",
    "        line=f.readline()\n",
    "        counter = len(line.split())\n",
    "        numWords.append(counter)  \n",
    "print('Negative files finished')\n",
    "\n",
    "numFiles = len(numWords)\n",
    "print('The total number of files is', numFiles)\n",
    "print('The total number of words in the files is', sum(numWords))\n",
    "print('The average number of words in the files is', sum(numWords)/len(numWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEKCAYAAAAvlUMdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d6043c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(numWords, 50)\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axis([0, 1200, 0, 8000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxSeqLength = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is easily the most underrated film inn the Brooks cannon. Sure, its flawed. It does not give a realistic view of homelessness (unlike, say, how Citizen Kane gave a realistic view of lounge singers, or Titanic gave a realistic view of Italians YOU IDIOTS). Many of the jokes fall flat. But still, this film is very lovable in a way many comedies are not, and to pull that off in a story about some of the most traditionally reviled members of society is truly impressive. Its not The Fisher King, but its not crap, either. My only complaint is that Brooks should have cast someone else in the lead (I love Mel as a Director and Writer, not so much as a lead).\n"
     ]
    }
   ],
   "source": [
    "fname = positiveFiles[3] #Can use any valid index (not just 3)\n",
    "with open(fname) as f:\n",
    "    for lines in f:\n",
    "        print(lines)\n",
    "        exit\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 删除标点符号、括号、问号等，只留下字母数字字符\n",
    "import re\n",
    "strip_special_chars = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "\n",
    "def cleanSentences(string):\n",
    "    string = string.lower().replace(\"<br />\", \" \")\n",
    "    return re.sub(strip_special_chars, \"\", string.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    37,     14,   2407, 201534,     96,  37314,    319,   7158,\n",
       "       201534,   6469,   8828,   1085,     47,   9703,     20,    260,\n",
       "           36,    455,      7,   7284,   1139,      3,  26494,   2633,\n",
       "          203,    197,   3941,  12739,    646,      7,   7284,   1139,\n",
       "            3,  11990,   7792,     46,  12608,    646,      7,   7284,\n",
       "         1139,      3,   8593,     81,  36381,    109,      3, 201534,\n",
       "         8735,    807,   2983,     34,    149,     37,    319,     14,\n",
       "          191,  31906,      6,      7,    179,    109,  15402,     32,\n",
       "           36,      5,      4,   2933,     12,    138,      6,      7,\n",
       "          523,     59,     77,      3, 201534,     96,   4246,  30006,\n",
       "          235,      3,    908,     14,   4702,   4571,     47,     36,\n",
       "       201534,   6429,    691,     34,     47,     36,  35404,    900,\n",
       "          192,     91,   4499,     14,     12,   6469,    189,     33,\n",
       "         1784,   1318,   1726,      6, 201534,    410,     41,    835,\n",
       "        10464,     19,      7,    369,      5,   1541,     36,    100,\n",
       "          181,     19,      7,    410,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstFile = np.zeros((maxSeqLength), dtype='int32')\n",
    "with open(fname) as f:\n",
    "    indexCounter = 0\n",
    "    line=f.readline()\n",
    "    cleanedLine = cleanSentences(line)\n",
    "    split = cleanedLine.split()\n",
    "    for word in split:\n",
    "        try:\n",
    "            firstFile[indexCounter] = wordsList.index(word)\n",
    "        except ValueError:\n",
    "            firstFile[indexCounter] = 399999 #Vector for unknown words\n",
    "        indexCounter = indexCounter + 1\n",
    "firstFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ids = np.zeros((numFiles, maxSeqLength), dtype='int32')\n",
    "# fileCounter = 0\n",
    "# for pf in positiveFiles:\n",
    "#    with open(pf, \"r\") as f:\n",
    "#        indexCounter = 0\n",
    "#        line=f.readline()\n",
    "#        cleanedLine = cleanSentences(line)\n",
    "#        split = cleanedLine.split()\n",
    "#        for word in split:\n",
    "#            try:\n",
    "#                ids[fileCounter][indexCounter] = wordsList.index(word)\n",
    "#            except ValueError:\n",
    "#                ids[fileCounter][indexCounter] = 399999 #Vector for unkown words\n",
    "#            indexCounter = indexCounter + 1\n",
    "#            if indexCounter >= maxSeqLength:\n",
    "#                break\n",
    "#        fileCounter = fileCounter + 1 \n",
    "\n",
    "# for nf in negativeFiles:\n",
    "#    with open(nf, \"r\") as f:\n",
    "#        indexCounter = 0\n",
    "#        line=f.readline()\n",
    "#        cleanedLine = cleanSentences(line)\n",
    "#        split = cleanedLine.split()\n",
    "#        for word in split:\n",
    "#            try:\n",
    "#                ids[fileCounter][indexCounter] = wordsList.index(word)\n",
    "#            except ValueError:\n",
    "#                ids[fileCounter][indexCounter] = 399999 #Vector for unkown words\n",
    "#            indexCounter = indexCounter + 1\n",
    "#            if indexCounter >= maxSeqLength:\n",
    "#                break\n",
    "#        fileCounter = fileCounter + 1 \n",
    "# #Pass into embedding function and see if it evaluates. \n",
    "\n",
    "# np.save('idsMatrix', ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids = np.load('./training_data/idsMatrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "def getTrainBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        if (i % 2 == 0): \n",
    "            num = randint(1,11499)\n",
    "            labels.append([1,0])\n",
    "        else:\n",
    "            num = randint(13499,24999)\n",
    "            labels.append([0,1])\n",
    "        arr[i] = ids[num-1:num]\n",
    "    return arr, labels\n",
    "\n",
    "def getTestBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        num = randint(11499,13499)\n",
    "        if (num <= 12499):\n",
    "            labels.append([1,0])\n",
    "        else:\n",
    "            labels.append([0,1])\n",
    "        arr[i] = ids[num-1:num]\n",
    "    return arr, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchSize = 24\n",
    "lstmUnits = 64\n",
    "numClasses = 2\n",
    "iterations = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "labels = tf.placeholder(tf.float32, [batchSize, numClasses])\n",
    "input_data = tf.placeholder(tf.int32, [batchSize, maxSeqLength])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = tf.Variable(tf.zeros([batchSize, maxSeqLength, numDimensions]),dtype=tf.float32)\n",
    "data = tf.nn.embedding_lookup(wordVectors,input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstmCell = tf.contrib.rnn.BasicLSTMCell(lstmUnits)\n",
    "lstmCell = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, output_keep_prob=0.75)\n",
    "value, _ = tf.nn.dynamic_rnn(lstmCell, data, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight = tf.Variable(tf.truncated_normal([lstmUnits, numClasses]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[numClasses]))\n",
    "value = tf.transpose(value, [1, 0, 2])\n",
    "#取最终的结果值\n",
    "last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "prediction = (tf.matmul(last, weight) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correctPred = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=labels))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1001/50000... loss 0.692835807800293... accuracy 0.5416666865348816...\n",
      "iteration 2001/50000... loss 0.7198070883750916... accuracy 0.5...\n",
      "iteration 3001/50000... loss 0.730301558971405... accuracy 0.3333333432674408...\n",
      "iteration 4001/50000... loss 0.5424675345420837... accuracy 0.6666666865348816...\n",
      "iteration 5001/50000... loss 0.5474028587341309... accuracy 0.7916666865348816...\n",
      "iteration 6001/50000... loss 0.7369804978370667... accuracy 0.5...\n",
      "iteration 7001/50000... loss 0.6959843039512634... accuracy 0.5416666865348816...\n",
      "iteration 8001/50000... loss 0.6027401685714722... accuracy 0.6666666865348816...\n",
      "iteration 9001/50000... loss 0.6570833325386047... accuracy 0.4166666567325592...\n",
      "iteration 10001/50000... loss 0.6449342370033264... accuracy 0.5833333134651184...\n",
      "saved to models/pretrained_lstm.ckpt-10000\n",
      "iteration 11001/50000... loss 0.6498488783836365... accuracy 0.5416666865348816...\n",
      "iteration 12001/50000... loss 0.5427295565605164... accuracy 0.75...\n",
      "iteration 13001/50000... loss 0.5140119791030884... accuracy 0.75...\n",
      "iteration 14001/50000... loss 0.44630154967308044... accuracy 0.75...\n",
      "iteration 15001/50000... loss 0.4354819357395172... accuracy 0.6666666865348816...\n",
      "iteration 16001/50000... loss 0.3166484534740448... accuracy 0.875...\n",
      "iteration 17001/50000... loss 0.32092687487602234... accuracy 0.8333333134651184...\n",
      "iteration 18001/50000... loss 0.31752678751945496... accuracy 0.875...\n",
      "iteration 19001/50000... loss 0.3309441804885864... accuracy 0.875...\n",
      "iteration 20001/50000... loss 0.21745897829532623... accuracy 0.9166666865348816...\n",
      "saved to models/pretrained_lstm.ckpt-20000\n",
      "iteration 21001/50000... loss 0.42144572734832764... accuracy 0.7916666865348816...\n",
      "iteration 22001/50000... loss 0.19494248926639557... accuracy 0.9166666865348816...\n",
      "iteration 23001/50000... loss 0.512983500957489... accuracy 0.8333333134651184...\n",
      "iteration 24001/50000... loss 0.12253747135400772... accuracy 0.9583333134651184...\n",
      "iteration 25001/50000... loss 0.2669636905193329... accuracy 0.9583333134651184...\n",
      "iteration 26001/50000... loss 0.1354103982448578... accuracy 0.9166666865348816...\n",
      "iteration 27001/50000... loss 0.2827714681625366... accuracy 0.875...\n",
      "iteration 28001/50000... loss 0.20138339698314667... accuracy 0.9166666865348816...\n",
      "iteration 29001/50000... loss 0.363887220621109... accuracy 0.875...\n",
      "iteration 30001/50000... loss 0.2448686808347702... accuracy 0.9166666865348816...\n",
      "saved to models/pretrained_lstm.ckpt-30000\n",
      "iteration 31001/50000... loss 0.13275082409381866... accuracy 0.9583333134651184...\n",
      "iteration 32001/50000... loss 0.18449486792087555... accuracy 0.9166666865348816...\n",
      "iteration 33001/50000... loss 0.16980735957622528... accuracy 0.9583333134651184...\n",
      "iteration 34001/50000... loss 0.05946145951747894... accuracy 0.9583333134651184...\n",
      "iteration 35001/50000... loss 0.0518355518579483... accuracy 1.0...\n",
      "iteration 36001/50000... loss 0.0469159334897995... accuracy 1.0...\n",
      "iteration 37001/50000... loss 0.0770982876420021... accuracy 0.9583333134651184...\n",
      "iteration 38001/50000... loss 0.02856440655887127... accuracy 1.0...\n",
      "iteration 39001/50000... loss 0.06490883976221085... accuracy 0.9583333134651184...\n",
      "iteration 40001/50000... loss 0.2936832904815674... accuracy 0.875...\n",
      "saved to models/pretrained_lstm.ckpt-40000\n",
      "iteration 41001/50000... loss 0.020127160474658012... accuracy 1.0...\n",
      "iteration 42001/50000... loss 0.020521407946944237... accuracy 1.0...\n",
      "iteration 43001/50000... loss 0.15693525969982147... accuracy 0.9583333134651184...\n",
      "iteration 44001/50000... loss 0.02062302455306053... accuracy 1.0...\n",
      "iteration 45001/50000... loss 0.03496300056576729... accuracy 1.0...\n",
      "iteration 46001/50000... loss 0.004296154715120792... accuracy 1.0...\n",
      "iteration 47001/50000... loss 0.08575945347547531... accuracy 0.9583333134651184...\n",
      "iteration 48001/50000... loss 0.015740729868412018... accuracy 1.0...\n",
      "iteration 49001/50000... loss 0.008722948841750622... accuracy 1.0...\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(iterations):\n",
    "    #Next Batch of reviews\n",
    "    nextBatch, nextBatchLabels = getTrainBatch();\n",
    "    sess.run(optimizer, {input_data: nextBatch, labels: nextBatchLabels}) \n",
    "    \n",
    "    if (i % 1000 == 0 and i != 0):\n",
    "        loss_ = sess.run(loss, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "        accuracy_ = sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "        \n",
    "        print(\"iteration {}/{}...\".format(i+1, iterations),\n",
    "              \"loss {}...\".format(loss_),\n",
    "              \"accuracy {}...\".format(accuracy_))    \n",
    "    #Save the network every 10,000 training iterations\n",
    "    if (i % 10000 == 0 and i != 0):\n",
    "        save_path = saver.save(sess, \"models/pretrained_lstm.ckpt\", global_step=i)\n",
    "        print(\"saved to %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/pretrained_lstm.ckpt-40000\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, tf.train.latest_checkpoint('models'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 91.6666686535\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 91.6666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 95.8333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 91.6666686535\n",
      "Accuracy for this batch: 75.0\n"
     ]
    }
   ],
   "source": [
    "iterations = 10\n",
    "for i in range(iterations):\n",
    "    nextBatch, nextBatchLabels = getTestBatch();\n",
    "    print(\"Accuracy for this batch:\", (sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels})) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
